{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# std python utility\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "# data wrangling and analysis\n",
    "import pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "# stats\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "\n",
    "# modelling \n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgbm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "pd.options.display.max_seq_items = 8000\n",
    "pd.options.display.max_rows = 8000\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_missing_report(df:pandas.DataFrame):\n",
    "    print(\"Report of Missing Values\")\n",
    "    all_cols = df.isna().any()\n",
    "    na_cols = [c for c in all_cols.index if all_cols[c] == True]\n",
    "    if len(na_cols) == 0:\n",
    "        print(\"There are no missing values...\")\n",
    "        return\n",
    "    na_cols.remove(\"Survived\") # random target feature column we DONT impute for\n",
    "    display(\"All columns:\",df.isna().any(), \"Missing cols:\", na_cols)\n",
    "    print()\n",
    "    for c in na_cols:\n",
    "        na_count = df[c].isna().sum()\n",
    "        total = len(df[c])\n",
    "        na_percent =  na_count / total * 100\n",
    "        print(\"{}: {} / {} instances missing --> {:1.5f}%\".format(c, na_count, total, na_percent))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directory setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hanz/github/kaggle-titanic')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/hanz/github/kaggle-titanic/input')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['train.csv', 'test.csv', 'gender_submission.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path(os.getcwd())\n",
    "DATA_DIR = ROOT / \"input\"\n",
    "PLOT_DIR = ROOT / \"plots\"\n",
    "\n",
    "display(ROOT, DATA_DIR)\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "train = pd.read_csv(DATA_DIR/\"train.csv\")\n",
    "test = pd.read_csv(DATA_DIR/\"test.csv\")\n",
    "# fix common lgbm error with not supporting JSON chars in feature name\n",
    "# reference: https://stackoverflow.com/questions/60582050/lightgbmerror-do-not-support-special-json-characters-in-feature-name-the-same\n",
    "train = train.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "test = test.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "train[\"Type\"] = 1\n",
    "test[\"Type\"] = 0\n",
    "## Join train and test sets in order to obtain the same number of features during categorical conversion\n",
    "full_data = pd.concat(objs=[train,test], axis=0).reset_index(drop=True)\n",
    "# Fill empty and NaNs values with NaN\n",
    "full_data = full_data.fillna(np.nan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute \"Age\" Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 16.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 16.0\n",
      "Filled using predicted value: 26.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 37.5\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 6.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 6.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 6.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 6.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 26.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 26.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 16.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 13.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 38.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 13.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 13.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 29.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 14.5\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 26.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 13.5\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 39.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 23.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using median value: 26.0\n",
      "Filled using predicted value: 16.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 26.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 30.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n",
      "Filled using predicted value: 25.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled using predicted value: 16.0\n"
     ]
    }
   ],
   "source": [
    "# Filling missing value of Age \n",
    "## Fill Age with the median age of similar rows according to Pclass, Parch and SibSp\n",
    "# Indices of NaN age rows\n",
    "index_NaN_age = list(full_data[\"Age\"][full_data[\"Age\"].isnull()].index) \n",
    "\n",
    "for i in index_NaN_age:\n",
    "    age_med = full_data[\"Age\"].median()\n",
    "    # search for an instance matching with the feature-criteria\n",
    "    age_pred = full_data[\"Age\"][(\n",
    "        (full_data['SibSp'] == full_data.iloc[i][\"SibSp\"]) & \n",
    "        (full_data['Parch'] == full_data.iloc[i][\"Parch\"]) & \n",
    "        (full_data['Pclass'] == full_data.iloc[i][\"Pclass\"]))].median()\n",
    "    # check if there exists an instance whose correlated features associate to an age\n",
    "    if not np.isnan(age_pred): \n",
    "        print(\"Filled using predicted value:\", age_pred) # DEBUG\n",
    "        full_data['Age'].iloc[i] = age_pred\n",
    "    # case in which there does not exist a matching instance of the feature criteria\n",
    "    else:\n",
    "        print(\"Filled using median value:\", age_med) # DEBUG\n",
    "        full_data['Age'].iloc[i] = age_med"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer \"Deck\" Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F', 'G']\n",
      "Counter({'F': 1, 'G': 1})\n",
      "['F', 'E']\n",
      "Counter({'F': 1, 'E': 1})\n",
      "['F', 'G']\n",
      "Counter({'F': 1, 'G': 1})\n",
      "['F', 'G']\n",
      "Counter({'F': 1, 'G': 1})\n",
      "['F', 'G']\n",
      "Counter({'F': 1, 'G': 1})\n",
      "['F', 'E']\n",
      "Counter({'F': 1, 'E': 1})\n",
      "['F', 'E']\n",
      "Counter({'F': 1, 'E': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BB</th>\n",
       "      <th>BBB</th>\n",
       "      <th>BBBB</th>\n",
       "      <th>C</th>\n",
       "      <th>CC</th>\n",
       "      <th>CCC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">D</th>\n",
       "      <th>DD</th>\n",
       "      <th colspan=\"3\" halign=\"left\">E</th>\n",
       "      <th>EE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F</th>\n",
       "      <th>FE</th>\n",
       "      <th>FG</th>\n",
       "      <th>G</th>\n",
       "      <th colspan=\"3\" halign=\"left\">M</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck     A   B BB BBB BBBB   C CC CCC   D    DD   E       EE   F    FE FG  G  \\\n",
       "Pclass   1   1  1   1    1   1  1   1   1  2  1   1  2  3  1   2  3  3  3  3   \n",
       "Count   22  48  8   4    5  80  8   6  38  6  2  33  4  3  1  13  1  3  4  5   \n",
       "Type    22  48  8   4    5  80  8   6  38  6  2  33  4  3  1  13  1  3  4  5   \n",
       "\n",
       "Deck     M            T  \n",
       "Pclass   1    2    3  1  \n",
       "Count   67  254  693  1  \n",
       "Type    67  254  693  1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex = r\"([a-zA-Z])\\d?\"\n",
    "test = 'F G73'\n",
    "re.findall(regex,test)\n",
    "full_data['Deck'] = full_data['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n",
    "\n",
    "df_all_decks = full_data.groupby(\n",
    "    ['Deck','Pclass']).count().drop(\n",
    "    columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n",
    "    'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(\n",
    "    columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "full_data = full_data.drop(\"Deck\", axis=1)\n",
    "for i, row in full_data.iterrows():\n",
    "    deck_str = row[\"Cabin\"]\n",
    "    # verify value is not null \n",
    "    if not pd.notnull(deck_str):\n",
    "        deck_str = \"M\" # M denoting missing\n",
    "        cabin = [deck_str]\n",
    "    else:\n",
    "        cabins = re.findall(regex,deck_str)\n",
    "    cabins = re.findall(regex,deck_str)\n",
    "    deck_count = Counter(cabins)\n",
    "    if deck_str != \"M\" and len(deck_count.keys()) > 1: # DEBUG\n",
    "        print(cabins)\n",
    "        print(deck_count)\n",
    "    for k in deck_count.keys():\n",
    "        # initialized case\n",
    "        if \"Deck_{}\".format(k) in full_data.columns:\n",
    "            pass\n",
    "        # uninitializated case\n",
    "        else:\n",
    "            pass\n",
    "        if \"Deck\" in full_data.columns:\n",
    "            full_data.loc[i,\"Deck\"] = \"\".join(cabins)\n",
    "        else:\n",
    "            full_data[\"Deck\"] = np.zeros(len(full_data))\n",
    "            full_data.loc[i,\"Deck\"] = \"\".join(cabins)\n",
    "    \n",
    "df_all_decks = full_data.groupby(['Deck','Pclass']).count().drop(\n",
    "columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Cabin',\n",
    "         'Fare', 'Embarked', 'PassengerId', 'Ticket'] + \n",
    "        [c for c in full_data.columns.to_list() if \"Deck_\" in c]\n",
    ").rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "df_all_decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>BB</th>\n",
       "      <th>BBB</th>\n",
       "      <th>BBBB</th>\n",
       "      <th>C</th>\n",
       "      <th>CC</th>\n",
       "      <th>CCC</th>\n",
       "      <th colspan=\"2\" halign=\"left\">D</th>\n",
       "      <th>DD</th>\n",
       "      <th colspan=\"3\" halign=\"left\">E</th>\n",
       "      <th>EE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">F</th>\n",
       "      <th>FE</th>\n",
       "      <th>FG</th>\n",
       "      <th>G</th>\n",
       "      <th colspan=\"3\" halign=\"left\">M</th>\n",
       "      <th>T</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>22</td>\n",
       "      <td>48</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck     A   B BB BBB BBBB   C CC CCC   D    DD   E       EE   F    FE FG  G  \\\n",
       "Pclass   1   1  1   1    1   1  1   1   1  2  1   1  2  3  1   2  3  3  3  3   \n",
       "Count   22  48  8   4    5  80  8   6  38  6  2  33  4  3  1  13  1  3  4  5   \n",
       "Type    22  48  8   4    5  80  8   6  38  6  2  33  4  3  1  13  1  3  4  5   \n",
       "\n",
       "Deck     M            T  \n",
       "Pclass   1    2    3  1  \n",
       "Count   67  254  693  1  \n",
       "Type    67  254  693  1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_decks = full_data.groupby(['Deck','Pclass']).count().drop(\n",
    "    columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Cabin',\n",
    "             'Fare', 'Embarked', 'PassengerId', 'Ticket'] + \n",
    "            [c for c in full_data.columns.to_list() if \"Deck_\" in c]\n",
    "    ).rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "df_all_decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 'ABC',\n",
       " 'B': 'ABC',\n",
       " 'BB': 'ABC',\n",
       " 'BBB': 'ABC',\n",
       " 'BBBB': 'ABC',\n",
       " 'C': 'ABC',\n",
       " 'CC': 'ABC',\n",
       " 'CCC': 'ABC',\n",
       " 'D': 'DE',\n",
       " 'DD': 'DE',\n",
       " 'E': 'DE',\n",
       " 'EE': 'DE',\n",
       " 'F': 'FG',\n",
       " 'FE': 'DE',\n",
       " 'FG': 'FG',\n",
       " 'G': 'FG',\n",
       " nan: 'M'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck_names = sorted(full_data.Deck.unique())\n",
    "deck_map = {}\n",
    "for d in deck_names:\n",
    "    if \"A\" in d:\n",
    "        deck_map[d] = \"ABC\"\n",
    "    elif \"B\" in d:\n",
    "        deck_map[d] = \"ABC\"\n",
    "    elif \"C\" in d:\n",
    "        deck_map[d] = \"ABC\"\n",
    "    elif \"D\" in d:\n",
    "        deck_map[d] = \"DE\"\n",
    "    elif \"E\" in d:\n",
    "        deck_map[d] = \"DE\"\n",
    "    elif \"F\" in d:\n",
    "        deck_map[d] = \"FG\"\n",
    "    elif \"G\" in d:\n",
    "        deck_map[d] = \"FG\"\n",
    "deck_map[np.nan] = \"M\"\n",
    "        \n",
    "deck_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Alone'] = (full_data['SibSp'] == 0) & (full_data['Parch'] == 0)\n",
    "\n",
    "deck_keys = list(full_data.Deck.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Type</th>\n",
       "      <th>Deck</th>\n",
       "      <th>Alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "      <td>ABC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>ABC</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1       0.0       3   \n",
       "1            2       1.0       1   \n",
       "2            3       1.0       3   \n",
       "3            4       1.0       1   \n",
       "4            5       0.0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  Type Deck  Alone  \n",
       "0      0         A/5 21171   7.2500   NaN        S     1    M  False  \n",
       "1      0          PC 17599  71.2833   C85        C     1  ABC  False  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S     1    M   True  \n",
       "3      0            113803  53.1000  C123        S     1  ABC  False  \n",
       "4      0            373450   8.0500   NaN        S     1    M   True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply map function for replacing exisitng labels with new label group\n",
    "full_data[\"Deck\"] = full_data[\"Deck\"].map(deck_map)\n",
    "full_data.Deck = full_data.Deck.replace(np.nan, \"M\")\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Deck</th>\n",
       "      <th>ABC</th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">FG</th>\n",
       "      <th colspan=\"3\" halign=\"left\">M</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>181</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>181</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alone</th>\n",
       "      <td>181</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>254</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Deck    ABC  DE         FG       M          \n",
       "Pclass    1   1   2  3   2   3   1    2    3\n",
       "Count   181  74  10  6  13  10  68  254  693\n",
       "Type    181  74  10  6  13  10  68  254  693\n",
       "Alone   181  74  10  6  13  10  68  254  693"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all_decks = full_data.groupby(['Deck','Pclass']).count().drop(\n",
    "    columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', 'Cabin',\n",
    "             'Fare', 'Embarked', 'PassengerId', 'Ticket'] + \n",
    "            [c for c in full_data.columns.to_list() if \"Deck_\" in c]\n",
    "    ).rename(columns={'Name': 'Count'}).transpose()\n",
    "\n",
    "df_all_decks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.drop(\"Cabin\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impute \"Embarked\" Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select instance in which Embarked feature is empty to fill\n",
    "full_data.Embarked = full_data.Embarked.fillna(\"S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8542"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "med_fare = full_data.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n",
    "med_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Fare'] = full_data['Fare'].fillna(med_fare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split back into original sets \n",
    "df_train = full_data[full_data[\"Type\"]==1]\n",
    "df_test = full_data[full_data[\"Type\"]==0]\n",
    "# remove column denoting set association\n",
    "df_train = df_train.drop(columns = ['Type'])\n",
    "df_test = df_test.drop(columns = ['Type', 'Survived'])\n",
    "# remove extra column\n",
    "\n",
    "display(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer \"Title\" Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['Title'] = full_data['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\n",
    "full_data['Title'] = full_data['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss/Mrs/Ms')\n",
    "full_data['Title'] = full_data['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr/Military/Noble/Clergy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Engineer \"Child\" Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data.loc[:, \"Child\"] = 1\n",
    "full_data.loc[full_data[\"Age\"]>=18, \"Child\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Non-Existence of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of Missing Values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'All columns:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "PassengerId    False\n",
       "Survived        True\n",
       "Pclass         False\n",
       "Name           False\n",
       "Sex            False\n",
       "Age            False\n",
       "SibSp          False\n",
       "Parch          False\n",
       "Ticket         False\n",
       "Fare           False\n",
       "Embarked       False\n",
       "Type           False\n",
       "Deck           False\n",
       "Alone          False\n",
       "Title          False\n",
       "Child          False\n",
       "dtype: bool"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Missing cols:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "show_missing_report(full_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report of Missing Values\n",
      "There are no missing values...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(891, 13)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_missing_report(df_train)\n",
    "df_train.shape\n",
    "# df_train\n",
    "# sorted(df_train.columns.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 12)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Features\n",
    "Features dropped here are "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Braund, Mr. Owen Harris'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-af6f4e04d103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m#Scaling Numerical columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mscaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_dataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mTransformer\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m         \"\"\"\n\u001b[0;32m--> 696\u001b[0;31m         X = self._validate_data(X, accept_sparse=('csr', 'csc'),\n\u001b[0m\u001b[1;32m    697\u001b[0m                                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                                 force_all_finite='allow-nan')\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     \u001b[0;34mf\"requires y to be passed, but the target y is None.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    599\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1779\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1780\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1781\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1782\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array_wrap__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Braund, Mr. Owen Harris'"
     ]
    }
   ],
   "source": [
    "target_col = [\"Survived\"]\n",
    "id_full_dataset = [\"Type\"]\n",
    "cat_cols   = full_data.nunique()[full_data.nunique() < 12].keys().tolist()\n",
    "cat_cols   = [x for x in cat_cols ]\n",
    "#numerical columns\n",
    "num_cols   = [x for x in full_data.columns if x not in cat_cols + target_col + id_full_dataset]\n",
    "#Binary columns with 2 values\n",
    "bin_cols   = full_data.nunique()[full_data.nunique() == 2].keys().tolist()\n",
    "#Columns more than 2 values\n",
    "multi_cols = [i for i in cat_cols if i not in bin_cols]\n",
    "\n",
    "#Label encoding Binary columns\n",
    "le = LabelEncoder()\n",
    "for i in bin_cols :\n",
    "    full_data[i] = le.fit_transform(full_data[i])\n",
    "    \n",
    "#Duplicating columns for multi value columns\n",
    "full_data = pd.get_dummies(data = full_data,columns = multi_cols )\n",
    "\n",
    "#Scaling Numerical columns\n",
    "std = StandardScaler()\n",
    "scaled = std.fit_transform(full_data[num_cols])\n",
    "scaled = pd.full_dataFrame(scaled,columns=num_cols)\n",
    "\n",
    "#dropping original values merging scaled values for numerical columns\n",
    "df_full_data_og = full_data.copy()\n",
    "full_data = full_data.drop(columns = num_cols,axis = 1)\n",
    "full_data = full_data.merge(scaled,left_index=True,right_index=True,how = \"left\")\n",
    "\n",
    "full_data = full_data.drop(columns = ['PassengerId'],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create CV Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train_enco.pop(\"Survived\")\n",
    "X = df_train_enco\n",
    "# Train_test split\n",
    "random_state = 1337\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Grid Search Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params = {\"early_stopping_rounds\" : 100, \n",
    "             \"eval_metric\" : 'auc', \n",
    "             \"eval_set\" : [(X_train,y_train)],\n",
    "             'eval_names': ['valid'],\n",
    "             'verbose': 0,\n",
    "             'categorical_feature': 'auto'}\n",
    "\n",
    "param_test = {'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n",
    "              'n_estimators' : [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000],\n",
    "              'num_leaves': sp_randint(6, 50), \n",
    "              'min_child_samples': sp_randint(100, 500), \n",
    "              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n",
    "              'subsample': sp_uniform(loc=0.2, scale=0.8), \n",
    "              'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n",
    "              'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n",
    "              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n",
    "              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n",
    "\n",
    "#number of combinations\n",
    "n_iter = 500 \n",
    "\n",
    "#intializing lgbm and lunching the search\n",
    "lgbm_clf = lgbm.LGBMClassifier(\n",
    "    random_state=random_state, \n",
    "    silent=True, \n",
    "    metric='None', n_jobs=4)\n",
    "\n",
    "grid_search = RandomizedSearchCV(\n",
    "    estimator=lgbm_clf, param_distributions=param_test, \n",
    "    n_iter=n_iter,\n",
    "    scoring='accuracy',\n",
    "    cv=5,\n",
    "    refit=True,\n",
    "    random_state=random_state,\n",
    "    verbose=True)\n",
    "\n",
    "grid_search.fit(X, y, **fit_params)\n",
    "print('Best score reached: {} with params: {} '.format(grid_search.best_score_, grid_search.best_params_))\n",
    "\n",
    "opt_parameters =  grid_search.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV Hyperparameter Found from Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"opt_parameters.json\", \"w\") as fh:\n",
    "    json.dump(opt_parameters, fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operate on Full Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf = lgbm.LGBMClassifier(**opt_parameters)\n",
    "lgbm_clf.fit(X, y)\n",
    "y_pred = lgbm_clf.predict(df_test)\n",
    "\n",
    "temp = pd.DataFrame(pd.read_csv( DATA_DIR / \"test.csv\")['PassengerId'])\n",
    "# temp['Survived'] = y_pred\n",
    "# temp.to_csv(\"../lgbm-submission.csv\", index = False)\n",
    "len(temp), len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv(\"lgbm-submission.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimination Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from yellowbrick.classifier import DiscriminationThreshold\n",
    "visualizer = DiscriminationThreshold(lgbm_clf)\n",
    "\n",
    "visualizer.fit(X, y)  \n",
    "visualizer.poof()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals \n",
    "import joblib\n",
    "joblib.dump(lgbm_clf, 'lgbm_model.pkl')\n",
    "# lgbm_clf.save_model(\"lgbm_model.txt\")\n",
    "# lgbm_clf.booster_.save_model(\"lgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm_loaded = joblib.load(\"lgbm_model.pkl\")\n",
    "# lgbm_loaded._Booster.save_model(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf._Booster.save_model(\"lgbm_model.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
